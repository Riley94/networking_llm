{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/base/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb import Settings\n",
    "import os\n",
    "from collections import Counter\n",
    "import kagglehub\n",
    "import re\n",
    "\n",
    "from data_loading.load_luflow import get_luflow\n",
    "from data_loading.tools import reduce_mem_usage\n",
    "\n",
    "vector_db_path = os.path.join(os.getcwd(), os.pardir, os.pardir, \"data/vector_db\")\n",
    "client = chromadb.PersistentClient(path=vector_db_path, settings=Settings(allow_reset=True, \n",
    "                                                                          anonymized_telemetry=False))\n",
    "\n",
    "use_luflow = False\n",
    "use_uq = True\n",
    "collection_name = \"packet_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 16.69 MB\n",
      "Decreased by 52.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/base/lib/python3.10/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/home/riley/base/lib/python3.10/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.100.148</td>\n",
       "      <td>65389</td>\n",
       "      <td>192.168.100.7</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>420</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35840</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>NF-BoT-IoT-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.100.148</td>\n",
       "      <td>11154</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DoS</td>\n",
       "      <td>NF-BoT-IoT-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.1.31</td>\n",
       "      <td>42062</td>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>1041</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NF-ToN-IoT-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.1.34</td>\n",
       "      <td>46849</td>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>9110</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NF-ToN-IoT-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>50360</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>1084</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "      <td>NF-ToN-IoT-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IPV4_SRC_ADDR  L4_SRC_PORT  IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n",
       "0  192.168.100.148        65389  192.168.100.7           80         6   \n",
       "1  192.168.100.148        11154  192.168.100.5           80         6   \n",
       "2     192.168.1.31        42062   192.168.1.79         1041         6   \n",
       "3     192.168.1.34        46849   192.168.1.79         9110         6   \n",
       "4     192.168.1.30        50360  192.168.1.152         1084         6   \n",
       "\n",
       "   L7_PROTO  IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  TCP_WIN_MAX_OUT  \\\n",
       "0       7.0       420        3          0         0  ...                0   \n",
       "1       7.0       280        2         40         1  ...                0   \n",
       "2       0.0        44        1         40         1  ...                0   \n",
       "3       0.0        44        1         40         1  ...                0   \n",
       "4       0.0        44        1         40         1  ...                0   \n",
       "\n",
       "   ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
       "0      35840             140             0               0               0   \n",
       "1          0               0             0               0               0   \n",
       "2          0               0             0               0               0   \n",
       "3          0               0             0               0               0   \n",
       "4          0               0             0               0               0   \n",
       "\n",
       "   FTP_COMMAND_RET_CODE  Label  Attack        Dataset  \n",
       "0                   0.0      1     DoS  NF-BoT-IoT-v2  \n",
       "1                   0.0      1     DoS  NF-BoT-IoT-v2  \n",
       "2                   0.0      0  Benign  NF-ToN-IoT-v2  \n",
       "3                   0.0      0  Benign  NF-ToN-IoT-v2  \n",
       "4                   0.0      0  Benign  NF-ToN-IoT-v2  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_luflow:\n",
    "    data = get_luflow(raw=True)\n",
    "else:\n",
    "    # Path to the cached dataset\n",
    "    cache_path = os.path.expanduser(\"~/.cache/kagglehub/datasets\")\n",
    "    data_path = os.path.join(cache_path, \"aryashah2k/nfuqnidsv2-network-intrusion-detection-dataset/versions/1\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        # Download latest version\n",
    "        data_path = kagglehub.dataset_download(\"aryashah2k/nfuqnidsv2-network-intrusion-detection-dataset\")\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(data_path, \"NF-UQ-NIDS-v2.csv\"), nrows=100_000)\n",
    "\n",
    "data = reduce_mem_usage(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack\n",
       "Benign            24793\n",
       "DDoS              21491\n",
       "DoS               17659\n",
       "scanning           3694\n",
       "Reconnaissance     2594\n",
       "xss                2426\n",
       "password           1129\n",
       "injection           714\n",
       "Bot                 148\n",
       "Brute Force         148\n",
       "Infilteration       122\n",
       "Exploits             26\n",
       "Fuzzers              18\n",
       "Backdoor             17\n",
       "Generic              13\n",
       "mitm                  3\n",
       "Shellcode             2\n",
       "Theft                 1\n",
       "Analysis              1\n",
       "ransomware            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IPV4_SRC_ADDR', 'L4_SRC_PORT', 'IPV4_DST_ADDR', 'L4_DST_PORT',\n",
       "       'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'OUT_PKTS',\n",
       "       'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS',\n",
       "       'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',\n",
       "       'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',\n",
       "       'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',\n",
       "       'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS',\n",
       "       'RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS',\n",
       "       'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
       "       'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES',\n",
       "       'NUM_PKTS_256_TO_512_BYTES', 'NUM_PKTS_512_TO_1024_BYTES',\n",
       "       'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT',\n",
       "       'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE',\n",
       "       'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE', 'Label', 'Attack', 'Dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_packet_documents_luflow(df):\n",
    "    documents = []\n",
    "    \n",
    "    print(\"Preparing packet documents...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        # Create a structured text representation of each flow\n",
    "        doc_parts = []\n",
    "        doc_parts.append(f\"Flow ID: {idx}\")\n",
    "        \n",
    "        # Basic flow metrics\n",
    "        doc_parts.append(f\"Average IPT: {row.get('avg_ipt', 'unknown')}\")\n",
    "        doc_parts.append(f\"Bytes In: {row.get('bytes_in', 'unknown')}\")\n",
    "        doc_parts.append(f\"Bytes Out: {row.get('bytes_out', 'unknown')}\")\n",
    "        \n",
    "        # Connection details\n",
    "        doc_parts.append(f\"Connection: {row.get('src_ip', 'unknown')}:{row.get('src_port', 'unknown')} → {row.get('dest_ip', 'unknown')}:{row.get('dest_port', 'unknown')}\")\n",
    "        \n",
    "        # Protocol information\n",
    "        doc_parts.append(f\"Protocol: {row.get('proto', 'unknown')}\")\n",
    "        \n",
    "        # Packet counts\n",
    "        doc_parts.append(f\"Packets In: {row.get('num_pkts_in', 'unknown')}\")\n",
    "        doc_parts.append(f\"Packets Out: {row.get('num_pkts_out', 'unknown')}\")\n",
    "        \n",
    "        # Entropy and statistical features\n",
    "        doc_parts.append(f\"Entropy: {row.get('entropy', 'unknown')}\")\n",
    "        doc_parts.append(f\"Total Entropy: {row.get('total_entropy', 'unknown')}\")\n",
    "        \n",
    "        # Timing information\n",
    "        doc_parts.append(f\"Start Time: {row.get('time_start', 'unknown')}\")\n",
    "        doc_parts.append(f\"End Time: {row.get('time_end', 'unknown')}\")\n",
    "        doc_parts.append(f\"Duration: {row.get('duration', 'unknown')}\")\n",
    "        \n",
    "        # Label and temporal context\n",
    "        doc_parts.append(f\"Label: {row.get('label', 'unknown')}\")\n",
    "        doc_parts.append(f\"Date: {row.get('Year', 'unknown')}-{row.get('Month', 'unknown')}-{row.get('Day', 'unknown')}\")\n",
    "        \n",
    "        # Combine all parts into a single document\n",
    "        document = \"\\n\".join(doc_parts)\n",
    "        \n",
    "        # Store the document with its metadata\n",
    "        documents.append({\n",
    "            \"id\": idx, \n",
    "            \"content\": document, \n",
    "            \"metadata\": {\n",
    "                \"avg_ipt\": row.get('avg_ipt', 0),\n",
    "                \"bytes_in\": row.get('bytes_in', 0),\n",
    "                \"bytes_out\": row.get('bytes_out', 0),\n",
    "                \"dest_ip\": row.get('dest_ip', ''),\n",
    "                \"dest_port\": row.get('dest_port', 0),\n",
    "                \"entropy\": row.get('entropy', 0),\n",
    "                \"num_pkts_out\": row.get('num_pkts_out', 0),\n",
    "                \"num_pkts_in\": row.get('num_pkts_in', 0),\n",
    "                \"proto\": row.get('proto', 0),\n",
    "                \"src_ip\": row.get('src_ip', ''),\n",
    "                \"src_port\": row.get('src_port', 0),\n",
    "                \"time_end\": row.get('time_end', 0),\n",
    "                \"time_start\": row.get('time_start', 0),\n",
    "                \"total_entropy\": row.get('total_entropy', 0),\n",
    "                \"label\": row.get('label', 0),\n",
    "                \"duration\": row.get('duration', 0),\n",
    "                \"year\": row.get('Year', 0),\n",
    "                \"month\": row.get('Month', 0),\n",
    "                \"day\": row.get('Day', 0)\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_packet_documents_uq(df):\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Create a structured text representation of each flow\n",
    "        doc_parts = []\n",
    "        doc_parts.append(f\"Flow ID: {idx}\")\n",
    "        \n",
    "        # Connection details\n",
    "        doc_parts.append(f\"Connection: {row.get('IPV4_SRC_ADDR', 'unknown')}:{row.get('L4_SRC_PORT', 'unknown')} → {row.get('IPV4_DST_ADDR', 'unknown')}:{row.get('L4_DST_PORT', 'unknown')}\")\n",
    "        \n",
    "        # Protocol information\n",
    "        doc_parts.append(f\"Protocol: {row.get('PROTOCOL', 'unknown')} (L7: {row.get('L7_PROTO', 'unknown')})\")\n",
    "        \n",
    "        # Volume metrics\n",
    "        doc_parts.append(f\"Traffic Volume: {row.get('IN_BYTES', 0) + row.get('OUT_BYTES', 0)} bytes total ({row.get('IN_PKTS', 0) + row.get('OUT_PKTS', 0)} packets)\")\n",
    "        doc_parts.append(f\"Inbound: {row.get('IN_BYTES', 0)} bytes in {row.get('IN_PKTS', 0)} packets\")\n",
    "        doc_parts.append(f\"Outbound: {row.get('OUT_BYTES', 0)} bytes in {row.get('OUT_PKTS', 0)} packets\")\n",
    "        \n",
    "        # TCP specific information\n",
    "        if row.get('PROTOCOL') == 6:  # TCP\n",
    "            doc_parts.append(f\"TCP Flags: {row.get('TCP_FLAGS', 'unknown')}\")\n",
    "            doc_parts.append(f\"Client TCP Flags: {row.get('CLIENT_TCP_FLAGS', 'unknown')}\")\n",
    "            doc_parts.append(f\"Server TCP Flags: {row.get('SERVER_TCP_FLAGS', 'unknown')}\")\n",
    "            doc_parts.append(f\"TCP Window Max (In/Out): {row.get('TCP_WIN_MAX_IN', 'unknown')}/{row.get('TCP_WIN_MAX_OUT', 'unknown')}\")\n",
    "            \n",
    "            # Retransmission stats\n",
    "            doc_parts.append(f\"Retransmissions: {row.get('RETRANSMITTED_IN_PKTS', 0) + row.get('RETRANSMITTED_OUT_PKTS', 0)} packets ({row.get('RETRANSMITTED_IN_BYTES', 0) + row.get('RETRANSMITTED_OUT_BYTES', 0)} bytes)\")\n",
    "        \n",
    "        # ICMP specific information\n",
    "        if row.get('PROTOCOL') == 1:  # ICMP\n",
    "            doc_parts.append(f\"ICMP Type: {row.get('ICMP_TYPE', 'unknown')}\")\n",
    "            doc_parts.append(f\"ICMP IPv4 Type: {row.get('ICMP_IPV4_TYPE', 'unknown')}\")\n",
    "        \n",
    "        # DNS specific information\n",
    "        if row.get('DNS_QUERY_ID') is not None:\n",
    "            doc_parts.append(f\"DNS Query ID: {row.get('DNS_QUERY_ID', 'unknown')}\")\n",
    "            doc_parts.append(f\"DNS Query Type: {row.get('DNS_QUERY_TYPE', 'unknown')}\")\n",
    "            doc_parts.append(f\"DNS TTL Answer: {row.get('DNS_TTL_ANSWER', 'unknown')}\")\n",
    "        \n",
    "        # FTP specific information\n",
    "        if row.get('FTP_COMMAND_RET_CODE') is not None:\n",
    "            doc_parts.append(f\"FTP Return Code: {row.get('FTP_COMMAND_RET_CODE', 'unknown')}\")\n",
    "        \n",
    "        # Timing information\n",
    "        doc_parts.append(f\"Flow Duration: {row.get('FLOW_DURATION_MILLISECONDS', 'unknown')} ms\")\n",
    "        doc_parts.append(f\"Duration In/Out: {row.get('DURATION_IN', 'unknown')}/{row.get('DURATION_OUT', 'unknown')}\")\n",
    "        \n",
    "        # Throughput\n",
    "        doc_parts.append(f\"Throughput Client→Server: {row.get('SRC_TO_DST_AVG_THROUGHPUT', 'unknown')} bytes/s\")\n",
    "        doc_parts.append(f\"Throughput Server→Client: {row.get('DST_TO_SRC_AVG_THROUGHPUT', 'unknown')} bytes/s\")\n",
    "        \n",
    "        # Packet size distribution\n",
    "        doc_parts.append(\"Packet Size Distribution:\")\n",
    "        doc_parts.append(f\"  ≤128 bytes: {row.get('NUM_PKTS_UP_TO_128_BYTES', 0)} packets\")\n",
    "        doc_parts.append(f\"  128-256 bytes: {row.get('NUM_PKTS_128_TO_256_BYTES', 0)} packets\")\n",
    "        doc_parts.append(f\"  256-512 bytes: {row.get('NUM_PKTS_256_TO_512_BYTES', 0)} packets\")\n",
    "        doc_parts.append(f\"  512-1024 bytes: {row.get('NUM_PKTS_512_TO_1024_BYTES', 0)} packets\")\n",
    "        doc_parts.append(f\"  1024-1514 bytes: {row.get('NUM_PKTS_1024_TO_1514_BYTES', 0)} packets\")\n",
    "        \n",
    "        # TTL and packet lengths\n",
    "        doc_parts.append(f\"TTL Range: {row.get('MIN_TTL', 'unknown')}-{row.get('MAX_TTL', 'unknown')}\")\n",
    "        doc_parts.append(f\"Packet Length Range: {row.get('MIN_IP_PKT_LEN', 'unknown')}-{row.get('MAX_IP_PKT_LEN', 'unknown')}\")\n",
    "        doc_parts.append(f\"Shortest/Longest Packet: {row.get('SHORTEST_FLOW_PKT', 'unknown')}/{row.get('LONGEST_FLOW_PKT', 'unknown')}\")\n",
    "        \n",
    "        # Classification information\n",
    "        if 'Label' in row:\n",
    "            doc_parts.append(f\"Label: {row.get('Label', 'unknown')}\")\n",
    "        if 'Attack' in row:\n",
    "            doc_parts.append(f\"Attack: {row.get('Attack', 'unknown')}\")\n",
    "        if 'Dataset' in row:\n",
    "            doc_parts.append(f\"Dataset: {row.get('Dataset', 'unknown')}\")\n",
    "        \n",
    "        # Combine all parts into a single document\n",
    "        document = \"\\n\".join(doc_parts)\n",
    "        \n",
    "        # Store the document with its metadata\n",
    "        # Convert metadata to appropriate types to avoid issues\n",
    "        metadata = {}\n",
    "        for col in row.index:\n",
    "            value = row.get(col)\n",
    "            # Handle NaN values and convert to basic types that ChromaDB can handle\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "            elif isinstance(value, (int, float, str, bool)):\n",
    "                metadata[col] = value\n",
    "            else:\n",
    "                # Convert other types to strings\n",
    "                metadata[col] = str(value)\n",
    "        \n",
    "        documents.append({\n",
    "            \"id\": idx, \n",
    "            \"content\": document, \n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(documents):\n",
    "    # Load a pretrained model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    print(\"Extracting text content from documents...\")\n",
    "    # Extract just the text content\n",
    "    texts = [doc[\"content\"] for doc in tqdm(documents)]\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    print(f\"Generated {len(embeddings)} embeddings\")\n",
    "    print(\"Adding embeddings to documents...\")\n",
    "    # Add embeddings to documents\n",
    "    for i, doc in tqdm(enumerate(documents)):\n",
    "        doc[\"embedding\"] = embeddings[i]\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_vector_db(documents, client):\n",
    "    # Create or get a collection\n",
    "    collection = client.get_or_create_collection(\"packet_data\")\n",
    "    \n",
    "    # Prepare data for insertion\n",
    "    ids = [str(doc[\"id\"]) for doc in documents]\n",
    "    embeddings = [doc[\"embedding\"].tolist() for doc in documents]\n",
    "    metadatas = [doc[\"metadata\"] for doc in documents]\n",
    "    documents_text = [doc[\"content\"] for doc in documents]\n",
    "    \n",
    "    # Set batch size within ChromaDB's limits\n",
    "    batch_size = 5000\n",
    "    \n",
    "    # Add documents in batches\n",
    "    total_docs = len(ids)\n",
    "    for i in tqdm(range(0, total_docs, batch_size)):\n",
    "        end_idx = min(i + batch_size, total_docs)\n",
    "        \n",
    "        # Create batch\n",
    "        batch_ids = ids[i:end_idx]\n",
    "        batch_embeddings = embeddings[i:end_idx]\n",
    "        batch_metadatas = metadatas[i:end_idx]\n",
    "        batch_documents = documents_text[i:end_idx]\n",
    "        \n",
    "        # Add batch to collection\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            embeddings=batch_embeddings,\n",
    "            metadatas=batch_metadatas,\n",
    "            documents=batch_documents\n",
    "        )\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_packets(query, collection, n=5):\n",
    "    # Load the same model used for document encoding\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Convert query to embedding\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERWRITE_DB = False\n",
    "\n",
    "if OVERWRITE_DB:\n",
    "    client.reset()\n",
    "\n",
    "test_size = 25\n",
    "train_size = len(data) - test_size\n",
    "\n",
    "if os.path.exists(vector_db_path) and not OVERWRITE_DB:\n",
    "    collection = client.get_collection(collection_name)\n",
    "    if use_luflow:\n",
    "        test_data = data.iloc[train_size:]\n",
    "    else:\n",
    "        test_data = data.iloc[train_size:].drop(columns=[\"Label\", \"Dataset\"])\n",
    "    \n",
    "else:\n",
    "    # Convert to documents\n",
    "    if use_luflow:\n",
    "        train_data = data.iloc[:train_size].drop(columns=[\"label\"])\n",
    "        test_data = data.iloc[train_size:]\n",
    "    else:\n",
    "        train_data = data.iloc[:train_size].drop(columns=[\"Label\", \"Dataset\"])\n",
    "        test_data = data.iloc[train_size:].drop(columns=[\"Label\", \"Dataset\"])\n",
    "    \n",
    "    train_documents = prepare_packet_documents_luflow(train_data) if use_luflow else prepare_packet_documents_uq(train_data)\n",
    "    # Create embeddings\n",
    "    embedded_docs = create_embeddings(train_documents)\n",
    "    collection = store_in_vector_db(embedded_docs, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = prepare_packet_documents_luflow(test_data) if use_luflow else prepare_packet_documents_uq(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flow ID: 100000\\nConnection: 172.31.65.105:56351 → 172.31.0.2:53\\nProtocol: 17 (L7: 0.0)\\nTraffic Volume: 219 bytes total (2 packets)\\nInbound: 77 bytes in 1 packets\\nOutbound: 142 bytes in 1 packets\\nDNS Query ID: 59387\\nDNS Query Type: 28\\nDNS TTL Answer: 60\\nFTP Return Code: 0.0\\nFlow Duration: 0 ms\\nDuration In/Out: 0/0\\nThroughput Client→Server: 616000 bytes/s\\nThroughput Server→Client: 1136000 bytes/s\\nPacket Size Distribution:\\n  ≤128 bytes: 1 packets\\n  128-256 bytes: 1 packets\\n  256-512 bytes: 0 packets\\n  512-1024 bytes: 0 packets\\n  1024-1514 bytes: 0 packets\\nTTL Range: 0-0\\nPacket Length Range: 77-142\\nShortest/Longest Packet: 77/142\\nAttack: <unknown>'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_doc = test_documents[0]\n",
    "example_doc['content'] = re.sub(r'Attack: .+', 'Attack: <unknown>', example_doc['content'])\n",
    "example_doc['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04535761848092079, -0.029125329107046127, -0.028575187548995018, -0.024307921528816223, -0.04005327820777893, -0.05888780206441879, -0.010500981472432613, -0.04569258913397789, 0.029122887179255486, 0.028962932527065277, -0.05667785927653313, 0.006247664336115122, -0.032113511115312576, -0.02683325856924057, -0.043476514518260956, -0.017615731805562973, -0.0389530174434185, -0.08204556256532669, 0.0436675101518631, -0.051193106919527054, 0.024619508534669876, 0.025424685329198837, -0.04024726152420044, -0.07850918173789978, -0.055708158761262894, 0.022892791777849197, -0.017443479970097542, 0.05648035183548927, -0.002502132672816515, -0.055365994572639465, 0.009432047605514526, 0.04266705363988876, -0.04710298404097557, 0.031492337584495544, -0.03549864515662193, 0.012455202639102936, 0.06329245865345001, 0.06478767096996307, -0.041807860136032104, 0.05146472901105881, 0.10004351288080215, -0.09022708237171173, 0.10147371888160706, 0.1192643940448761, -0.044388893991708755, -0.013103637844324112, -0.05804675817489624, 0.07768771797418594, 0.0017638147110119462, -0.07085476815700531, 0.013867998495697975, 0.032753173261880875, 0.010256672278046608, 0.09641256928443909, 0.02654927968978882, -0.07096219807863235, -0.08580563217401505, -0.04302341118454933, 0.018616827204823494, 0.07051735371351242, -0.03024810552597046, 0.01866661012172699, -0.021135849878191948, 0.013016029261052608, -0.011634866707026958, -0.04159695282578468, 0.002467071171849966, 0.04283919185400009, 0.04558093473315239, -0.0033799700904637575, -0.03421527147293091, 0.044677913188934326, -0.11015176773071289, 0.015431116335093975, -0.006272949278354645, -0.003471905831247568, 0.0017593911616131663, -0.003509367583319545, -0.06257200241088867, -0.010921809822320938, 0.07368192076683044, -0.0010517333867028356, -0.03212718665599823, 0.036511119455099106, -0.023693719878792763, 0.005969126243144274, -0.0017254211707040668, -0.0004908611299470067, 0.01736241765320301, 0.015370954759418964, -0.0679808109998703, 0.08791280537843704, 0.006038544699549675, 0.046652134507894516, 0.05413557216525078, 0.09816720336675644, 0.03612838685512543, -0.049316201359033585, -0.09003926068544388, 0.04781961441040039, 0.03822724521160126, -0.009208530187606812, -0.07903249561786652, -0.06307513266801834, 0.0028847246430814266, -0.025078723207116127, 0.013826573267579079, 0.08758000284433365, 0.07925914227962494, 0.06835242360830307, -0.03477029129862785, -0.015679165720939636, 0.016957342624664307, -0.027363527566194534, -0.030422860756516457, -0.01964350789785385, -0.07165202498435974, 0.05441742390394211, 0.02471119910478592, 0.03394331783056259, 0.01249015610665083, 0.024116871878504753, -0.048434387892484665, -0.01910192333161831, -0.01855984702706337, -0.015274321660399437, 0.05995899438858032, 1.1062484030724451e-32, 0.006848610006272793, 0.030137281864881516, -0.08152952790260315, -0.03844790160655975, -0.012135481461882591, 0.014649495482444763, 0.041676394641399384, 0.02332494966685772, -0.07804084569215775, 0.0158879105001688, -0.11805733293294907, -0.06377711147069931, -0.033036116510629654, -0.00640286086127162, 0.021936509758234024, 0.01322265900671482, 0.040500156581401825, 0.029954250901937485, 0.033866576850414276, 0.04805343970656395, -0.002475334331393242, -0.052099116146564484, -0.0024978192523121834, -0.0547887347638607, 0.046471938490867615, 0.04321923106908798, -0.1010994017124176, -0.027996763586997986, 0.02940652333199978, 0.012973916716873646, 0.02534862607717514, -0.03359797224402428, -0.06274617463350296, 0.0613357312977314, 0.04483471065759659, -0.037320081144571304, -0.033433642238378525, -0.007779959123581648, -0.023746231570839882, 0.0277485940605402, -0.062234342098236084, -0.009185687638819218, -0.1258881390094757, -0.02039175108075142, -0.0818018764257431, -0.08259555697441101, -0.0433148629963398, -0.07283087819814682, -0.051875993609428406, 0.04301625117659569, 0.019531164318323135, 0.028640013188123703, -0.08112257719039917, 0.00722374115139246, 0.04585416987538338, -0.04436768963932991, 0.048484351485967636, 0.09076902270317078, 0.009755677543580532, 0.18360763788223267, -0.013298931531608105, -0.022213837131857872, -0.0355571024119854, -0.06376011669635773, 0.10646513849496841, -0.009864266961812973, -0.06071270629763603, 0.03283098340034485, 0.019425388425588608, 0.018651049584150314, 0.015894446521997452, 0.023258883506059647, 0.11583710461854935, 0.0461084209382534, 0.013007104396820068, 0.008589440956711769, -0.031072579324245453, -0.013771217316389084, 0.015175722539424896, 0.048442114144563675, -0.07508960366249084, -0.006435480434447527, 0.03770655766129494, 0.055245377123355865, -0.0034532174468040466, 0.04766421765089035, 0.039736971259117126, -0.024416964501142502, -0.09333400428295135, 0.04174137860536575, -0.08839345723390579, -0.045544665306806564, 0.018014008179306984, -0.08265745639801025, -0.020753325894474983, -1.1821574936131298e-32, -0.1041569858789444, 0.07481571286916733, -0.08944129943847656, 0.03279826417565346, 0.01893678680062294, -0.07354900240898132, 0.06961759179830551, 0.12868165969848633, 0.03134298697113991, 0.036872971802949905, 0.0507989339530468, 0.0393761545419693, 0.028915902599692345, -0.05586938560009003, 0.0627506673336029, -0.06396543234586716, 0.045447494834661484, -0.04970795288681984, -0.06430884450674057, -0.009952702559530735, -0.061453476548194885, 0.0652458518743515, -0.07170706987380981, -0.005625717807561159, 0.002949248068034649, 0.002283110748976469, 0.013514128513634205, -0.001792183960787952, -0.02912946417927742, 0.0038751098327338696, 0.07767928391695023, -0.01709822192788124, -0.08136892318725586, 0.012934761121869087, 0.03515317663550377, 0.0027676885947585106, 0.048124704509973526, 0.12677250802516937, 0.03412283957004547, -0.009313058108091354, 0.08003000915050507, 0.011960752308368683, -0.06407688558101654, 0.027040565386414528, -0.0040314518846571445, -0.003988403826951981, 0.011031592264771461, -0.0005198674043640494, -0.01905791088938713, -0.00815313309431076, 0.008805982768535614, 0.04383932799100876, 0.008363948203623295, 0.06053938344120979, 0.04341786727309227, 0.007792623247951269, 0.04662266746163368, 0.024084854871034622, 0.040986426174640656, -0.029195476323366165, 0.13360905647277832, -0.08547128736972809, -0.06394510716199875, 0.07309400290250778, 0.12530624866485596, 0.011905591003596783, -0.02627284824848175, 0.0316556878387928, -0.01917550154030323, 0.06265190988779068, 0.047488514333963394, 0.015082052908837795, -0.0016542242374271154, 0.03946538642048836, 0.09204979240894318, -0.022782154381275177, 0.05834858492016792, 0.06042945012450218, -0.06077946349978447, 0.09321774542331696, -0.11036103218793869, 0.0715925320982933, -0.04918292909860611, -0.04654763638973236, 0.05233457684516907, 0.01251120027154684, 0.09494708478450775, 0.0068907951936125755, 0.027635307982563972, 0.005340214353054762, -0.0026166571769863367, 0.035415373742580414, -0.08992286771535873, -0.009053985588252544, 0.023091329261660576, -5.554461424139845e-08, -0.07858416438102722, -0.0265819001942873, -0.06804756820201874, 0.017643580213189125, -0.003358413465321064, 0.13317474722862244, -0.019347555935382843, -0.022238774225115776, -0.029294120147824287, -0.04076695442199707, 0.049605999141931534, -0.044681616127491, -0.017545102164149284, -0.0458839014172554, 0.020581021904945374, -0.039994049817323685, -0.006330410018563271, -0.031737085431814194, -0.053561173379421234, -0.13518351316452026, -0.05311186984181404, -0.007458722684532404, -0.09729565680027008, -0.033941611647605896, -0.0733095183968544, -0.047610439360141754, 0.06061572954058647, 0.013128361664712429, -0.02924753725528717, -0.045277129858732224, -0.022938881069421768, -0.010192684829235077, -0.06508180499076843, -0.009458796121180058, -0.008527981117367744, 0.1082250252366066, -0.08528124541044235, 0.0009619321208447218, -0.017668481916189194, 0.052247460931539536, -0.005994934123009443, -0.03264623507857323, 0.014934028498828411, 0.030444566160440445, 0.03690243512392044, 0.00999980978667736, -0.02233719639480114, -0.0018438707338646054, 0.006551678292453289, -0.04941249266266823, 0.026236923411488533, 0.032843731343746185, -0.0041122641414403915, -0.0011206280905753374, 0.0791856124997139, 0.02741941623389721, -0.048478201031684875, -0.10656749457120895, -0.05385510250926018, -0.010853958316147327, -0.001956700813025236, 0.035559993237257004, -0.01094642374664545, 0.01975727640092373]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Benign', 5)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = retrieve_similar_packets(example_doc['content'], collection, n=5)\n",
    "metadata = results['metadatas']\n",
    "attacks = [match_dict['Attack'] for match_dict in metadata[0]]\n",
    "attack_counts = Counter(attacks)\n",
    "attack_counts.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benign'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_doc['metadata']['Attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:17<00:00,  1.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_vector_db(test_docs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for doc in tqdm(test_docs):\n",
    "        # Query the collection\n",
    "        doc_copy = doc.copy()\n",
    "        doc_copy['content'] = re.sub(r'Attack: .+', 'Attack: <unknown>', doc_copy['content'])\n",
    "        results = retrieve_similar_packets(doc_copy['content'], collection, n=5)\n",
    "        metadata = results['metadatas']\n",
    "        attacks = [match_dict['Attack'] for match_dict in metadata[0]]\n",
    "        attack_counts = Counter(attacks)\n",
    "        most_common_attack = attack_counts.most_common(1)[0][0]\n",
    "        \n",
    "        if most_common_attack == doc['metadata']['Attack']:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return correct / total\n",
    "    \n",
    "test_accuracy = validate_vector_db(test_documents)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flow ID: 80000\\nConnection: 114.43.207.102:50369 → 172.31.66.28:445\\nProtocol: 6 (L7: 0.0)\\nTraffic Volume: 840 bytes total (9 packets)\\nInbound: 498 bytes in 5 packets\\nOutbound: 342 bytes in 4 packets\\nTCP Flags: 30\\nClient TCP Flags: 26\\nServer TCP Flags: 30\\nTCP Window Max (In/Out): 16560/8192\\nRetransmissions: 0 packets (0 bytes)\\nDNS Query ID: 0\\nDNS Query Type: 0\\nDNS TTL Answer: 0\\nFTP Return Code: 0.0\\nFlow Duration: 0 ms\\nDuration In/Out: 0/0\\nThroughput Client→Server: 3984000 bytes/s\\nThroughput Server→Client: 2736000 bytes/s\\nPacket Size Distribution:\\n  ≤128 bytes: 6 packets\\n  128-256 bytes: 3 packets\\n  256-512 bytes: 0 packets\\n  512-1024 bytes: 0 packets\\n  1024-1514 bytes: 0 packets\\nTTL Range: 100-100\\nPacket Length Range: 40-171\\nShortest/Longest Packet: 40/171\\nAttack: Benign'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = prepare_packet_documents_uq(data.iloc[:(len(data)) - 1].drop(columns=[\"Label\", \"Dataset\"]))\n",
    "test_docs[80_000]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_filters(collection, query_text, metadata_filters, n_results=5):\n",
    "    \"\"\"Query with both semantic search and metadata filters.\"\"\"\n",
    "    \n",
    "    # Load embedding model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Encode the query\n",
    "    query_embedding = model.encode(query_text).tolist()\n",
    "    \n",
    "    # Convert flat filters to proper ChromaDB format\n",
    "    # ChromaDB requires a single operator at the top level\n",
    "    formatted_where = {\"$and\": []}\n",
    "    \n",
    "    for key, value in metadata_filters.items():\n",
    "        if isinstance(value, dict):\n",
    "            # This is already an operator (like {\"$gt\": 4.0})\n",
    "            formatted_where[\"$and\"].append({key: value})\n",
    "        else:\n",
    "            # This is a direct value match\n",
    "            formatted_where[\"$and\"].append({key: {\"$eq\": value}})\n",
    "    \n",
    "    # Search the collection with properly formatted filters\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        where=formatted_where,\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
